:jbake-title: Prompt-Engineering fÃ¼r Entwickler
:jbake-type: page
:jbake-status: published

:diagram-server-url: https://kroki.io
:diagram-server-type: kroki_io

== ğŸ‡©ğŸ‡ª Prompt-Engineering fÃ¼r Entwickler

=== Hintergrund

In einer Zeit, in der Large-Language-Models wie OpenAI's GPT-Serie immer mehr an Bedeutung gewinnen, stehen Entwickler und Software-Architekten vor der spannenden Herausforderung, diese Technologien in Chat-Anwendungen optimal zu nutzen. Die QualitÃ¤t der Interaktion mit solchen Modellen hÃ¤ngt maÃŸgeblich davon ab, wie prÃ¤zise und durchdacht unsere Anfragen formuliert werden.

=== Inhalt

Der erste Teil des Talks taucht tief in die Kunst des "Prompt-Engineerings" ein. Hier betrachten wir, wie durch das gezielte "Priming" die KI in bestimmte Antwort- oder Denkrichtungen gelenkt werden kann. Dieses subtile Steuern der KI ermÃ¶glicht es, Antworten zu erhalten, die genau auf den Kontext und die BedÃ¼rfnisse des Anwenders abgestimmt sind. Weiterhin beleuchten wir die Unterschiede und Anwendungsgebiete von Few-Shots, Zero-Shots und Many-Shots. Jeder dieser AnsÃ¤tze besitzt eigene StÃ¤rken, und es ist entscheidend, zu verstehen, wann und wie sie am besten in Chat-Anwendungen eingesetzt werden kÃ¶nnen. Besonders herausgestellt wird die Herausforderung der begrenzten Token-Zahl und Strategien, um innerhalb dieser Begrenzung klare, kohÃ¤rente und hilfreiche Antworten zu erzielen.

Als besonderen Bonus des Talks gehen wir kurz auf die Nutzung von Embeddings ein, die es ermÃ¶glichen, themenspezifische Kommunikationen mit der KI zu fÃ¼hren und somit die Relevanz der Antworten noch weiter zu erhÃ¶hen.

=== Zielgruppe

Der Talk wendet sich an Java-Entwickler, Software-Architekten und Technologie-Experten, die den Einsatz von LLM in Chat-Anwendungen in Betracht ziehen oder bereits erste Erfahrungen gesammelt haben.


=== Referenzen

* https://techstories.dbsystel.de/blog/2023/2023-11-08-prompt-engineering.html[Slides]